pracmel1.prediction.resp <- prediction.responses[1:5]
pracmel1.prediction.RT <- prediction.RTs[1:5]
pracmel1.closure.resp <- closure.responses[1:5]
pracmel1.closure.RT <- closure.RTs[1:5]
pracmel1 <- as.tibble(cbind(pracmel1.info, pracmel1.files, pracmel1.prediction.resp, pracmel1.prediction.RT, pracmel1.closure.resp, pracmel1.closure.RT))
#PracMel2
pracmel2.index <- grep(pattern = "PracMel2", procedure.info)
#Collect all relevant info
pracmel2.info <- procedure.info[pracmel2.index]
pracmel2.files <- file.info[pracmel2.index]
pracmel2.precision.resp <- precision.responses[1:5]
pracmel2.precision.RT <- precision.RTs[1:5]
pracmel2 <- as.tibble(cbind(pracmel2.info, pracmel2.files, pracmel2.precision.resp, pracmel2.precision.RT))
#Prediction/closure trials ------------------------
predclose.index <- grep(pattern = "PredClos", procedure.info)
#Collect all relevant info
predclose.info <- procedure.info[predclose.index]
predclose.files <- file.info[predclose.index]
predclose.prediction.resp <- prediction.responses[6:length(prediction.responses)]
predclose.prediction.RT <- prediction.RTs[6:length(prediction.RTs)]
predclose.closure.resp <- closure.responses[6:length(closure.responses)]
predclose.closure.RT <- closure.RTs[6:length(closure.RTs)]
pred <- as.tibble(cbind(predclose.info, predclose.files, predclose.prediction.resp, predclose.prediction.RT))
clos <- as.tibble(cbind(predclose.info, predclose.files, predclose.closure.resp, predclose.closure.RT))
#Precision trials ---------------------------------
cert.index <- grep(pattern = "Cert", procedure.info)
#Collect all relevant info
cert.info <- procedure.info[cert.index]
cert.files <- file.info[cert.index]
cert.precision.resp <- precision.responses[6:length(precision.responses)]
cert.precision.RT <- precision.RTs[6:length(precision.responses)]
cert <- as.tibble(cbind(cert.info, cert.files, cert.precision.resp, cert.precision.RT))
#-------------------------------------------------
#Clean up each rating type dataframe
#-------------------------------------------------
#PracMel1
pracmel1$Participant <- part.id
pracmel1$Time <- time
prac1.procedure.index <- grep(pattern = "PracMel1", procedure.info)
pracmel1$MelodyID <- melody.ids[prac1.procedure.index]
pracmel1$NoteID <- note.ids[prac1.procedure.index]
pracmel1 <- select(pracmel1, Time, Participant, MelodyID, NoteID, pracmel1.prediction.resp, pracmel1.prediction.RT, pracmel1.closure.resp, pracmel1.closure.RT)
colnames(pracmel1) <- c("Time", "Participant", "MelodyID", "NoteID", "PredictionRESP", "PredictionRT", "ClosureRESP", "ClosureRT")
#PracMel2
pracmel2$Participant <- part.id
pracmel2$Time <- time
prac2.procedure.index <- grep(pattern = "PracMel2", procedure.info)
pracmel2$MelodyID <- melody.ids[prac2.procedure.index]
pracmel2$NoteID <- note.ids[prac2.procedure.index]
pracmel2 <- select(pracmel2, Time, Participant, MelodyID, NoteID, pracmel2.precision.resp, pracmel2.precision.RT)
colnames(pracmel2) <- c("Time", "Participant", "MelodyID", "NoteID", "PrecisionRESP", "PrecisionRT")
#Prediction
pred$Participant <- part.id
pred$Time <- time
pred$RatingType <- "Prediction"
predclos.procedure.index <- grep(pattern = "PredClos", procedure.info)
pred$MelodyID <- melody.ids[predclos.procedure.index]
pred$NoteID <- note.ids[predclos.procedure.index]
pred <- select(pred, Time, Participant, MelodyID, NoteID, RatingType, predclose.prediction.resp, predclose.prediction.RT)
colnames(pred) <- c("Time", "Participant", "MelodyID", "NoteID", "RatingType", "Rating", "RT")
#Closure
clos$Participant <- part.id
clos$Time <- time
clos$RatingType <- "Closure"
predclos.procedure.index <- grep(pattern = "PredClos", procedure.info)
clos$MelodyID <- melody.ids[predclos.procedure.index]
clos$NoteID <- note.ids[predclos.procedure.index]
clos <- select(clos, Time, Participant, MelodyID, NoteID, RatingType, predclose.closure.resp, predclose.closure.RT)
colnames(clos) <- c("Time", "Participant", "MelodyID", "NoteID", "RatingType", "Rating", "RT")
#Precision
cert$Participant <- part.id
cert$Time <- time
cert$RatingType <- "Precision"
cert.procedure.index <- grep(pattern = "Cert", procedure.info)
cert$MelodyID <- melody.ids[cert.procedure.index]
cert$NoteID <- note.ids[cert.procedure.index]
cert <- select(cert, Time, Participant, MelodyID, NoteID, RatingType, cert.precision.resp, cert.precision.RT)
colnames(cert) <- c("Time", "Participant", "MelodyID", "NoteID", "RatingType", "Rating", "RT")
View(cert)
View(clos)
View(pred)
human.data <- as.data.frame(rbind(data[[3]], data[[4]], data[[5]]))
View(cert)
View(clos)
colnames(data[[3]])
colnames(data[[4]])
colnames(data[[5]])
##Combine all participants' data
practice1data <- rbind(practice1data, pracmel1)
practice1data <- NULL
practice2data <- NULL
predictiondata <- NULL
closuredata <- NULL
precisiondata <- NULL
##Combine all participants' data
practice1data <- rbind(practice1data, pracmel1)
practice2data <- rbind(practice2data, pracmel2)
predictiondata <- rbind(predictiondata, pred)
closuredata <- rbind(closuredata, clos)
precisiondata <- rbind(precisiondata, cert)
##Insert data frame of each rating type into a list for output
data[[1]] <- as.data.frame(practice1data)
data[[2]] <- as.data.frame(practice2data)
data[[3]] <- as.data.frame(predictiondata)
data[[4]] <- as.data.frame(closuredata)
data[[5]] <- as.data.frame(precisiondata)
human.data <- as.data.frame(rbind(data[[3]], data[[4]], data[[5]]))
View(human.data)
View(human.data)
human.before.prediction <- filter(human.data, RatingType == "Prediction")
human.before.precision <- filter(human.data, RatingType == "Precision")
paired.human.data <- cbind(human.before.prediction, human.before.precision)
human.before.prediction <- human.before.prediction[1:8,]
paired.human.data <- cbind(human.before.prediction, human.before.precision)
View(paired.human.data)
paired.human.data <- inner_join(human.before.prediction, human.before.precision)
paired.human.data <- cbind(human.before.prediction, human.before.precision)
colnames(paired.human.data)
sd <- .5/.5
plot(rnorm(n = 100, mean = .5, sd = 1))
y <- rnorm(n = 100, mean = .5, sd = 1)
x <- 1:100
plot(x, y)
y <- dnorm(n = 100, mean = .5, sd = 1)
x <- 1:100
plot(x, y)
y <- dnorm(mean = .5, sd = 1)
x <- 1:100
plot(x, y)
y <- dnorm(x = c(1:100), mean = .5, sd = 1)
x <- 1:100
plot(x, y)
mean <- .5
sd <- 1
x <- seq(-4, 4, length=100)*sd + mean
hx <- dnorm(x, mean, sd)
x
hs
hx
plot(x, hx, type = "n")
plot(x, hx)
sd <- .5/.2
sd <- 2.5
x <- seq(-4, 4, length=100)*sd + mean
hx <- dnorm(x, mean, sd)
plot(x, hx)
mean <- 1
sd <- .5
x <- seq(-4, 4, length=100)*sd + mean
hx <- dnorm(x, mean, sd)
plot(x, hx)
mean <- 1
sd <- .8
x <- seq(-4, 4, length=100)*sd + mean
hx <- dnorm(x, mean, sd)
plot(x, hx)
1/.8
#Import IDyOM data
idyom.data <- read_csv("IDyOM_data.csv",
col_types = cols(X1 = col_skip()))
library(tidyverse)
library(lme4)
#Import IDyOM data
idyom.data <- read_csv("IDyOM_data.csv",
col_types = cols(X1 = col_skip()))
#Import behavioural data
human.data <- read_csv("Human_data.csv")
#set fixed effect parameters
b0 <- 4.5 #intercept
b1 <- .5 #slope
#set random effect parameters
S0s_sd <- .56 #by-subject random intercept sd (for the paper simulation it was 100 for an intercept of 800, so 4.5/8 = .56)
I0i_sd <- .4 #by-item random intercept sd
S1s_sd <- .4 #by-subject random slope sd
scor <- .2 #correlation between intercept and slope
err_sd <- 1.12 #residual error sd (x2 by-subject sd)
#define # of subjects and items
nsubj <- 30
nitem <- c(before = 8, after = 8)
#simulation function
my_sim_data <- function(
nsubj, #number of subjects
nitem = c(before = 8, after = 8), #number of items ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
b0, #grand mean
b1, # effect of category
I0i_sd, #by-item random intercept sd
S0s_sd, #by-subject random intercept sd
S1s_sd, #by-subject random slope sd
scor, #correlation between intercept and slope
err_sd){ #resicual standard deviation
#simulate items
items <- faux::sim_design(
between = list(category = c("before", "after")), ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
n = nitem,
sd = I0i_sd,
dv = "I0i",
id = "item_id",
plot = FALSE
)
#effect code category
items$cat <- recode(items$category, "before" = -0.25, "after" = 0.25) ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
#simulate subjects
subjects <- faux::sim_design(
within = list(effect = c(S0s = "By-subject random intercepts",
S1s = "by-subject random slopes")),
n = nsubj,
sd = c(S0s_sd, S1s_sd),
r = scor,
id = "subj_id",
plot = FALSE
)
#simulate trials
dat_sim <- crossing(subj_id = subjects$subj_id,
item_id = items$item_id) %>%
inner_join(subjects, "subj_id") %>%
inner_join(items, "item_id") %>%
mutate(err = rnorm(nrow(.), mean = 0, sd = err_sd)) %>%
mutate(RT = b0 + I0i + S0s + (b1 + S1s) * cat + err) %>%
select(subj_id, item_id, category, cat, RT)
dat_sim
}
#generate simulated data
dat_sim <- my_sim_data()
#simulation function
my_sim_data <- function(
nsubj, #number of subjects
nitem = c(before = 8, after = 8), #number of items ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
b0, #grand mean
b1, # effect of category
I0i_sd, #by-item random intercept sd
S0s_sd, #by-subject random intercept sd
S1s_sd, #by-subject random slope sd
scor, #correlation between intercept and slope
err_sd){ #resicual standard deviation
#simulate items
items <- faux::sim_design(
between = list(category = c("before", "after")), ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
n = nitem,
sd = I0i_sd,
dv = "I0i",
id = "item_id",
plot = FALSE
)
#effect code category
items$cat <- recode(items$category, "before" = -0.25, "after" = 0.25) ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
#simulate subjects
subjects <- faux::sim_design(
within = list(effect = c(S0s = "By-subject random intercepts",
S1s = "by-subject random slopes")),
n = nsubj,
sd = c(S0s_sd, S1s_sd),
r = scor,
id = "subj_id",
plot = FALSE
)
#simulate trials
dat_sim <- crossing(subj_id = subjects$subj_id,
item_id = items$item_id) %>%
inner_join(subjects, "subj_id") %>%
inner_join(items, "item_id") %>%
mutate(err = rnorm(nrow(.), mean = 0, sd = err_sd)) %>%
mutate(RT = b0 + I0i + S0s + (b1 + S1s) * cat + err) %>%
select(subj_id, item_id, category, cat, RT)
dat_sim
}
I0i_sd <- .4 #by-item random intercept sd
#generate simulated data
dat_sim <- my_sim_data()
#generate simulated data
dat_sim <- my_sim_data(I0i_sd = .4)
#generate simulated data
dat_sim <- my_sim_data(I0i_sd = .4, nsubj = 30)
#generate simulated data
dat_sim <- my_sim_data(nsubj = nsubj, nitem = nitem, b0 = b0, b1 = b1, I0i_sd = I0i_sd, S0s_sd = S0s_sd, S1s_sd = S1s_sd, scor = scor, err_sd = err_sd)
View(dat_sim)
#simulation function
my_sim_data <- function(
nsubj, #number of subjects
nitem = c(before = 8, after = 8), #number of items ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
b0, #grand mean
b1, # effect of category
I0i_sd, #by-item random intercept sd
S0s_sd, #by-subject random intercept sd
S1s_sd, #by-subject random slope sd
scor, #correlation between intercept and slope
err_sd){ #resicual standard deviation
#simulate items
items <- faux::sim_design(
between = list(category = c("before", "after")), ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
n = nitem,
sd = I0i_sd,
dv = "I0i",
id = "item_id",
plot = FALSE
)
#effect code category
items$cat <- recode(items$category, "before" = -0.25, "after" = 0.25) ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
#simulate subjects
subjects <- faux::sim_design(
within = list(effect = c(S0s = "By-subject random intercepts",
S1s = "by-subject random slopes")),
n = nsubj,
sd = c(S0s_sd, S1s_sd),
r = scor,
id = "subj_id",
plot = FALSE
)
#simulate trials
dat_sim <- crossing(subj_id = subjects$subj_id,
item_id = items$item_id) %>%
inner_join(subjects, "subj_id") %>%
inner_join(items, "item_id") %>%
mutate(err = rnorm(nrow(.), mean = 0, sd = err_sd)) %>%
mutate(Rating = b0 + I0i + S0s + (b1 + S1s) * cat + err) %>%
select(subj_id, item_id, category, cat, Rating)
dat_sim
}
#generate simulated data
dat_sim <- my_sim_data(nsubj = nsubj, nitem = nitem, b0 = b0, b1 = b1, I0i_sd = I0i_sd, S0s_sd = S0s_sd, S1s_sd = S1s_sd, scor = scor, err_sd = err_sd)
View(dat_sim)
max(dat_sim$Rating)
min(dat_sim$Rating)
#simulation function
my_sim_data <- function(
nsubj, #number of subjects
nitem = c(before = 8, after = 8), #number of items ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
b0, #grand mean
b1, # effect of category
I0i_sd, #by-item random intercept sd
S0s_sd, #by-subject random intercept sd
S1s_sd, #by-subject random slope sd
scor, #correlation between intercept and slope
err_sd){ #resicual standard deviation
#simulate items
items <- faux::sim_design(
between = list(category = c("before", "after")), ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
n = nitem,
sd = I0i_sd,
dv = "I0i",
id = "item_id",
plot = FALSE
)
#effect code category
items$cat <- recode(items$category, "before" = -0.25, "after" = 0.25) ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
#simulate subjects
subjects <- faux::sim_design(
within = list(effect = c(S0s = "By-subject random intercepts",
S1s = "by-subject random slopes")),
n = nsubj,
sd = c(S0s_sd, S1s_sd),
r = scor,
id = "subj_id",
plot = FALSE
)
#simulate trials
dat_sim <- crossing(subj_id = subjects$subj_id,
item_id = items$item_id) %>%
inner_join(subjects, "subj_id") %>%
inner_join(items, "item_id") %>%
mutate(err = rtruncnorm(n = nrow(.), a = 1, b = 7, mean = 0, sd = err_sd)) %>%
mutate(Rating = b0 + I0i + S0s + (b1 + S1s) * cat + err) %>%
select(subj_id, item_id, category, cat, Rating)
dat_sim
}
#generate simulated data
dat_sim <- my_sim_data(nsubj = nsubj, nitem = nitem, b0 = b0, b1 = b1, I0i_sd = I0i_sd, S0s_sd = S0s_sd, S1s_sd = S1s_sd, scor = scor, err_sd = err_sd)
library(truncnorm)
#simulation function
my_sim_data <- function(
nsubj, #number of subjects
nitem = c(before = 8, after = 8), #number of items ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
b0, #grand mean
b1, # effect of category
I0i_sd, #by-item random intercept sd
S0s_sd, #by-subject random intercept sd
S1s_sd, #by-subject random slope sd
scor, #correlation between intercept and slope
err_sd){ #resicual standard deviation
#simulate items
items <- faux::sim_design(
between = list(category = c("before", "after")), ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
n = nitem,
sd = I0i_sd,
dv = "I0i",
id = "item_id",
plot = FALSE
)
#effect code category
items$cat <- recode(items$category, "before" = -0.25, "after" = 0.25) ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
#simulate subjects
subjects <- faux::sim_design(
within = list(effect = c(S0s = "By-subject random intercepts",
S1s = "by-subject random slopes")),
n = nsubj,
sd = c(S0s_sd, S1s_sd),
r = scor,
id = "subj_id",
plot = FALSE
)
#simulate trials
dat_sim <- crossing(subj_id = subjects$subj_id,
item_id = items$item_id) %>%
inner_join(subjects, "subj_id") %>%
inner_join(items, "item_id") %>%
mutate(err = rtruncnorm(n = nrow(.), a = 1, b = 7, mean = 0, sd = err_sd)) %>%  ##Truncation used so that data fall between 1 and 7
mutate(Rating = b0 + I0i + S0s + (b1 + S1s) * cat + err) %>%
select(subj_id, item_id, category, cat, Rating)
dat_sim
}
#generate simulated data
dat_sim <- my_sim_data(nsubj = nsubj, nitem = nitem, b0 = b0, b1 = b1, I0i_sd = I0i_sd, S0s_sd = S0s_sd, S1s_sd = S1s_sd, scor = scor, err_sd = err_sd)
View(dat_sim)
max(dat_sim$Rating)
min(dat_sim$Rating)
#set random effect parameters
S0s_sd <- .5 #by-subject random intercept sd (for the paper simulation it was 100 for an intercept of 800, so 4.5/8 = .56)
I0i_sd <- .2 #by-item random intercept sd
S1s_sd <- .2 #by-subject random slope sd
scor <- .2 #correlation between intercept and slope
err_sd <- 1 #residual error sd (x2 by-subject sd)
#simulation function
my_sim_data <- function(
nsubj, #number of subjects
nitem = c(before = 8, after = 8), #number of items ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
b0, #grand mean
b1, # effect of category
I0i_sd, #by-item random intercept sd
S0s_sd, #by-subject random intercept sd
S1s_sd, #by-subject random slope sd
scor, #correlation between intercept and slope
err_sd){ #resicual standard deviation
#simulate items
items <- faux::sim_design(
between = list(category = c("before", "after")), ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
n = nitem,
sd = I0i_sd,
dv = "I0i",
id = "item_id",
plot = FALSE
)
#effect code category
items$cat <- recode(items$category, "before" = -0.25, "after" = 0.25) ###CHANGE BASED ON EXPERIMENT BEING SIMULATED###
#simulate subjects
subjects <- faux::sim_design(
within = list(effect = c(S0s = "By-subject random intercepts",
S1s = "by-subject random slopes")),
n = nsubj,
sd = c(S0s_sd, S1s_sd),
r = scor,
id = "subj_id",
plot = FALSE
)
#simulate trials
dat_sim <- crossing(subj_id = subjects$subj_id,
item_id = items$item_id) %>%
inner_join(subjects, "subj_id") %>%
inner_join(items, "item_id") %>%
mutate(err = rnorm(n = nrow(.), mean = 0, sd = err_sd)) %>%
mutate(Rating = b0 + I0i + S0s + (b1 + S1s) * cat + err) %>%
select(subj_id, item_id, category, cat, Rating)
dat_sim
}
#generate simulated data
dat_sim <- my_sim_data(nsubj = nsubj, nitem = nitem, b0 = b0, b1 = b1, I0i_sd = I0i_sd, S0s_sd = S0s_sd, S1s_sd = S1s_sd, scor = scor, err_sd = err_sd)
View(dat_sim)
hist(dat_sim$Rating)
#fit a linear mixed-effects model to the data
mod_sim <- lmer(Rating ~ 1 + cat + (1|item_id) + (1+cat|subj_id), data = dat_sim, REML = FALSE)
?isSingular
summary(mod_sim, corr = FALSE)
#get a tidy table of results
broom.mixed::tidy(mod_sim) %>%
mutate(sim = c(b0, b1, S0s_sd, S1s_sd, scor, I0i_sd, err_sd)) %>%
select(1:3, 9, 4:8)
#set up the power function
my_lmer_power <- function(...){
dat_sim <- my_sim_data(...)
mod_sim <- lmer(Rating ~ cat + (1|item_id) + (1+cat|subj_id),
dat_sim, REML = FALSE)
broom.mixed::tidy(mod_sim)
}
#run model with default parameters
my_lmer_power()
#run model with default parameters
my_lmer_power(nsubj = nsubj, nitem = nitem, b0 = b0, b1 = b1, I0i_sd = I0i_sd, S0s_sd = S0s_sd, S1s_sd = S1s_sd, scor = scor, err_sd = err_sd)
#run simulations and save to a file
reps <- 100
sims <- purrr::map_df(1:reps, ~my_lmer_power())
getwd)
getwd())
getwd()
#run simulations and save to a file
reps <- 100
sims <- purrr::map_df(1:reps, ~my_lmer_power(nsubj = nsubj, nitem = nitem, b0 = b0, b1 = b1, I0i_sd = I0i_sd, S0s_sd = S0s_sd, S1s_sd = S1s_sd, scor = scor, err_sd = err_sd))
write_csv(sims, "Mixedeffects_simulation.csv")
#read saved simulation data
sims <- read_csv("R_mixedeffects_simulation.csv", col_types = cols(
group = col_factor(ordered = TRUE),
term = col_factor(ordered = TRUE)
))
#calculate mean estimates and power for specified alpha
alpha <- 0.05
sims %>%
filter(effect == "fixed") %>%
group_by(term) %>%
summarise(mean_estimate = mean(estimate),
mean_se = mean(std.error),
power = mean(p.value < alpha)
)
#fit a linear mixed-effects model to the data
mod_sim <- lmer(Rating ~ 1 + category + (1|item_id) + (1+cat|subj_id), data = dat_sim, REML = FALSE)
summary(mod_sim, corr = FALSE)
